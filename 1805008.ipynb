{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Input:\n",
    "\t# input shape: (batch_size, #features)\n",
    "\t# output shape: (batch_size, #features)\n",
    "\n",
    "\tdef __init__(self, inputFeatures) -> None:\n",
    "\t\tself.inputShape = (-1, inputFeatures)\n",
    "\t\tself.outputShape = self.inputShape\n",
    "\t\n",
    "\tdef forward(self, x):\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef backward(self, gradientLossWRTOutput, _):\n",
    "\t\treturn gradientLossWRTOutput\n",
    "\t\n",
    "\n",
    "\n",
    "class Dense:\n",
    "\t# input shape: (batch_size, #features)\n",
    "\t# output shape: (batch_size, #nodes)\n",
    "\n",
    "\tdef __init__(self, numNodes) -> None:\n",
    "\t\tself.numNodes = numNodes\n",
    "\t\n",
    "\t# input shape: (batch_size, #features)\n",
    "\tdef initPipeline(self, inputFeatures):\n",
    "\t\tself.features = inputFeatures\n",
    "\n",
    "\t\tself.weights = np.random.randn(self.numNodes, inputFeatures)\n",
    "\t\tself.bias = np.random.randn(self.numNodes)\n",
    "\t\tself.outputShape = (-1, self.numNodes)\n",
    "\n",
    "\t# x shape: (batch_size, #features)\n",
    "\tdef forward(self, x):\n",
    "\t\tself.x = x\n",
    "\t\tself.y = np.dot(self.weights, x.T) + self.bias\n",
    "\t\treturn self.y\n",
    "\t\n",
    "\t# gradientLossWRTOutput shape: (batch_size, #nodes)\n",
    "\n",
    "\tdef backward(self, gradientLossWRTOutput,learningRate):\n",
    "\t\t\n",
    "\t\tgradientLossWRTInput = np.dot(gradientLossWRTOutput, self.weights)\n",
    "\t\t\n",
    "\t\tgradientLossWRTWeights = np.dot(gradientLossWRTOutput.T, self.x)\n",
    "\t\tgradientLossWRTBias = gradientLossWRTOutput.sum(axis=0)\n",
    "\t\t\n",
    "\t\tself.weights -= learningRate * gradientLossWRTWeights\n",
    "\t\tself.bias -= learningRate * gradientLossWRTBias\n",
    "\n",
    "\t\treturn gradientLossWRTInput\n",
    "\t\t\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "\tdef __init__(self) -> None:\n",
    "\t\tpass\n",
    "\n",
    "\t# input shape: (batch_size, #features)\n",
    "\t# output shape: (batch_size, #features)\n",
    "\n",
    "\tdef initPipeline(self, inputShape):\n",
    "\t\tself.inputShape = inputShape\n",
    "\t\tself.outputShape = inputShape\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tself.x = x\n",
    "\t\tself.y =  np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "\t\treturn self.y\n",
    "\t\n",
    "\t# gradientLossWRTOutput shape: (batch_size, #features)\n",
    "\n",
    "\tdef backward(self, gradientLossWRTOutput, _):\n",
    "\t\t# gradientOutputWRT\n",
    "\n",
    "\t\tn , m = self.y.shape\n",
    "\n",
    "\t\tgradientOutputWRTInput = np.repeat(self.y, m, axis=0).reshape(n, m, m)\n",
    "\t\tgradientOutputWRTInput = np.multiply(gradientOutputWRTInput, np.transpose(gradientOutputWRTInput, axes=(0, 2, 1))) * -1\n",
    "\n",
    "\t\tdiagElems = np.reshape(self.y, (n,  m , 1))\n",
    "\t\tdiagElems = diagElems * (1 - diagElems)\n",
    "\t\tdiagElems = np.eye(m) * diagElems\n",
    "\t\tmask = np.eye(m, dtype=bool)\n",
    "\t\tmask = np.tile(mask, (n, 1)).reshape(n, m, m)\n",
    "\t\tgradientOutputWRTInput[mask] = 0\n",
    "\t\tgradientOutputWRTInput = gradientOutputWRTInput + diagElems\n",
    "\n",
    "\t\tjacobian_matrix = np.zeros((n, m, m))\n",
    "\n",
    "\t\tfor i in range(n):\n",
    "\t\t\ts = self.forward(self.x[i])\n",
    "\t\t\tfor j in range(n):\n",
    "\t\t\t\tfor k in range(n):\n",
    "\t\t\t\t\tjacobian_matrix[i, j, k] = s[j] * (int(j == k) - s[k])\n",
    "\n",
    "\n",
    "\t\tprint(np.isclose(jacobian_matrix, gradientOutputWRTInput).all())\n",
    "\n",
    "\t\tgradientLossWRTInput = np.multiply(gradientOutputWRTInput, np.expand_dims(gradientLossWRTOutput, -1))\n",
    "\n",
    "\t\treturn gradientLossWRTInput\n",
    "\t\n",
    "\n",
    "class Relu:\n",
    "\tdef __init__(self) -> None:\n",
    "\t\tpass\n",
    "\n",
    "\tdef initPipeline(self, inputShape):\n",
    "\t\tself.inputShape = inputShape\n",
    "\t\tself.outputShape = inputShape\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tself.x = x\n",
    "\t\tself.y = np.maximum(x, 0)\n",
    "\t\treturn self.y\n",
    "\n",
    "\t# gradientLossWRTOutput shape: (batch_size, #features)\n",
    "\tdef backward(self, gradientLossWRTOutput, _):\n",
    "\t\tgradientOutputWRTInput = np.where(self.x > 0, 1, 0)\n",
    "\t\tgradientLossWRTInput = np.multiply(gradientOutputWRTInput, gradientLossWRTOutput)\n",
    "\t\treturn gradientLossWRTInput\n",
    "\t\n",
    "\t\n",
    "\n",
    "class Model:\n",
    "\tdef __init__(self, layers) -> None:\n",
    "\t\tfor layer in layers:\n",
    "\t\t\tif isinstance(layer, Input):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tlayer.initPipeline(layer.inputShape)\n",
    "\t\t\n",
    "\t\tself.layers = layers\n",
    "\t\n",
    "\tdef predict(self, x):\n",
    "\t\tfor layer in self.layers:\n",
    "\t\t\tx = layer.forward(x)\n",
    "\t\treturn x\n",
    "\n",
    "\tdef backprop(self,yTrue, yPred, learningRate):\n",
    "\t\tgradientLossWRTOutput = - yTrue / yPred\n",
    "\t\tfor layer in reversed(self.layers):\n",
    "\t\t\tgradientLossWRTOutput = layer.backward(gradientLossWRTOutput, learningRate)\n",
    "\n",
    "\n",
    "\t\n",
    "\n",
    "def main():\n",
    "\tpass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()\n",
    "\n",
    "\n",
    "# Your initial array of shape (n, m)\n",
    "# original_array = np.array([[1, 2, 3],\n",
    "# \t\t\t\t\t\t[4, 5, 6]])\n",
    "\n",
    "# n, m = original_array.shape\n",
    "\n",
    "# # Repeat each row m times\n",
    "# repeated_rows = np.repeat(original_array, m, axis=0)\n",
    "\n",
    "# # Reshape the repeated array to (n, m, m)\n",
    "# result_array = repeated_rows.reshape(n, m, m)\n",
    "\n",
    "# # print(result_array)\n",
    "\n",
    "# # print(np.reshape(original_array, (n,  m , 1)))\n",
    "\n",
    "# diagElems = np.reshape(original_array, (n,  m , 1))\n",
    "# # diagElems = original_array\n",
    "# diagElems = diagElems * (1 - diagElems)\n",
    "# diagElems = np.eye(m) * diagElems\n",
    "# print(diagElems)\n",
    "\n",
    "# mask = np.eye(m, dtype=bool)\n",
    "# mask = np.tile(mask, (n, 1)).reshape(n, m, m)\n",
    "\n",
    "# # result_array = np.fill_diagonal(result_array, diagElems)\n",
    "# # np.fill_diagonal(result_array, 0)\n",
    "# result_array[mask] = 0\n",
    "# result_array = result_array + diagElems\n",
    "\n",
    "# print(result_array)\n",
    "# # print(diagElems)\n",
    "\n",
    "# print(np.multiply(result_array, np.transpose(result_array, axes=(0, 2, 1))))\n",
    "\n",
    "\n",
    "# print(np.multiply(result_array, np.reshape(original_array, (n, m, 1))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
